{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authors: Tlachac, et al\n",
    "#Paper: \"Automated Construction of Lexicons to Improve Depression Screening with Text Messages\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import collections\n",
    "import operator\n",
    "import argparse\n",
    "import random\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import metrics\n",
    "from statistics import mean \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "from sklearn.decomposition import PCA, KernelPCA, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"featuresCombined5r\"\n",
    "data = pd.read_csv(name + \".csv\")\n",
    "label = \"scores\"\n",
    "split = 10\n",
    "numTexts = 5\n",
    "print(data.shape)\n",
    "\n",
    "#binary labels\n",
    "d10 = []\n",
    "s1 = []\n",
    "for i in range(0, data.shape[0]):\n",
    "    if int(data.scores[i]) >= split:\n",
    "        d10.append(1)\n",
    "    else:\n",
    "        d10.append(0)\n",
    "data[label] = d10\n",
    "\n",
    "data = data[data[\"NumTexts\"]>=numTexts]\n",
    "print(data.shape)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featureEs = [\"Chi\"]\n",
    "modelTypelist = [\"NB\",\"LR1\",\"SVC1\", \"SVC2\", \"SVC3\", \"SVC4\", \"kNN3\", \"kNN5\"]\n",
    "    \n",
    "#create lists to populate\n",
    "flist = [] \n",
    "mlist = []\n",
    "llist = []\n",
    "featureList = []\n",
    "f1List = []\n",
    "accuracyList = []\n",
    "truePosList = []\n",
    "trueNegList = []\n",
    "falsePosList = []\n",
    "falseNegList = []\n",
    "predictions = []\n",
    "rseed = []\n",
    "\n",
    "for run in range(0,100):\n",
    "    r = random.randint(0, 100000)\n",
    "\n",
    "    #train/test split    \n",
    "    df_train, df_test = train_test_split(data, test_size=0.3, stratify=data[[label]], random_state = r)\n",
    "    trainids = list(df_train[\"id\"])\n",
    "    testids = list(df_test[\"id\"])\n",
    "    print(data.shape)\n",
    "    testdata = data[data['id'].isin(testids)]\n",
    "    print(testdata.shape)\n",
    "    traindata = data[data['id'].isin(trainids)]\n",
    "    print(traindata.shape)\n",
    "\n",
    "    #limit to features\n",
    "    testContent = testdata[testdata.columns[5:]]\n",
    "    print(testContent.shape)\n",
    "    trainContent = traindata[traindata.columns[5:]]\n",
    "    print(trainContent.shape)\n",
    "\n",
    "    #NEED TO SCALE BEFORE FEATURE SELECTION/REDUCATION\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()  \n",
    "    np_scaled = min_max_scaler.fit_transform(trainContent)\n",
    "    featureSubset = pd.DataFrame(np_scaled)\n",
    "    np_scaled2 =  min_max_scaler.transform(testContent)\n",
    "    testSubset = pd.DataFrame(np_scaled2)\n",
    "\n",
    "    target = list(traindata[label])\n",
    "\n",
    "    for featureE in featureEs:\n",
    "\n",
    "        featureDF = []\n",
    "        testDFs = []\n",
    "\n",
    "        if featureE == \"Chi\":\n",
    "            nFeatureList = list(np.arange(1,11,1))\n",
    "\n",
    "            for numberOfFeatures in nFeatureList:\n",
    "                chisetup = SelectKBest(chi2, k=numberOfFeatures)\n",
    "                chisetup = chisetup.fit(featureSubset, target)\n",
    "                featureSubset2 = chisetup.transform(featureSubset)\n",
    "                featureSubset2=pd.DataFrame(featureSubset2).assign(target = target)\n",
    "                featureDF.append(featureSubset2)\n",
    "                testSubset2 = chisetup.transform(testSubset)\n",
    "                testDFs.append(pd.DataFrame(testSubset2))\n",
    "\n",
    "        for f in range(0, len(featureDF)):\n",
    "\n",
    "            train_phq9 = featureDF[f]\n",
    "            X_test = testDFs[f]\n",
    "\n",
    "            # upsampling \n",
    "            #Count 1s and 0s\n",
    "            ones = len(train_phq9.loc[train_phq9['target'] == 1])\n",
    "            zeros = len(train_phq9.loc[train_phq9['target'] == 0])\n",
    "            if ones >= zeros:\n",
    "                majority = 1\n",
    "                minority = 0\n",
    "            else:\n",
    "                majority = 0\n",
    "                minority = 1\n",
    "\n",
    "\n",
    "            # Upsample TrainingSet \n",
    "            train_majority = train_phq9[train_phq9.target==majority]\n",
    "            train_minority = train_phq9[train_phq9.target==minority]\n",
    "\n",
    "            #print(\"train_majority =\"  + str(len(train_majority)))\n",
    "            #print(\"train_minority =\"  + str(len(train_minority)))\n",
    "\n",
    "            # Upsample minority class\n",
    "            train_minority_upsampled = resample(train_minority, \n",
    "                                             replace=True,     # sample with replacement\n",
    "                                             n_samples=len(train_majority),    # to match majority class\n",
    "                                             random_state=42) # reproducible results\n",
    "\n",
    "            # Combine majority class with upsampled minority class\n",
    "            train_phq9 = pd.concat([train_majority, train_minority_upsampled])\n",
    "\n",
    "            #seperate features and target\n",
    "            y_train = train_phq9[\"target\"]\n",
    "            X_train = train_phq9.drop(columns = \"target\")\n",
    "\n",
    "            for modelType in modelTypelist:\n",
    "\n",
    "                #add data to lists\n",
    "                llist.append(label)\n",
    "                featureList.append(f +1)\n",
    "                flist.append(featureE)\n",
    "                mlist.append(modelType)\n",
    "\n",
    "                #chose model type\n",
    "                if modelType == \"SVC1\":\n",
    "                    clf = svm.SVC(kernel='rbf', random_state=r)\n",
    "                elif modelType == \"SVC2\":\n",
    "                    clf = svm.SVC(kernel='linear', random_state=r)\n",
    "                elif modelType == \"SVC3\":\n",
    "                    clf = svm.SVC(kernel='poly', random_state=r)\n",
    "                elif modelType == \"SVC4\":\n",
    "                    clf = svm.SVC(kernel='sigmoid', random_state=r)\n",
    "                elif modelType == \"kNN3\":\n",
    "                    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "                elif modelType == \"kNN5\":\n",
    "                    clf = KNeighborsClassifier(n_neighbors=5)\n",
    "                elif modelType == \"LR1\":\n",
    "                    clf = LogisticRegression(random_state=r)\n",
    "                elif modelType == \"NB\":\n",
    "                    clf = GaussianNB()\n",
    "\n",
    "\n",
    "                #train model and make predictions\n",
    "                clf.fit(X_train, y_train)\n",
    "                \n",
    "                print(X_train.columns)\n",
    "                print(X_test.columns)\n",
    "                y_pred = clf.predict(X_test)\n",
    "\n",
    "                #evaluate model\n",
    "                conf_mat = confusion_matrix(list(testdata[label]), y_pred)\n",
    "                TN = conf_mat[0][0]\n",
    "                TP = conf_mat[1][1]\n",
    "                FP = conf_mat[0][1]\n",
    "                FN = conf_mat[1][0]\n",
    "                precision = TP/(TP+FP)\n",
    "                sensitivity = TP/(TP+FN)\n",
    "                f1 = (2*precision*sensitivity)/(precision + sensitivity)\n",
    "                accuracy = (TP+TN)/(TN+TP+FP+FN)\n",
    "\n",
    "                #populate lists with results\n",
    "                f1List.append(f1)\n",
    "                accuracyList.append(accuracy)\n",
    "                truePosList.append(TP)\n",
    "                trueNegList.append(TN)\n",
    "                falsePosList.append(FP)\n",
    "                falseNegList.append(FN)\n",
    "                predictions.append(y_pred)\n",
    "                rseed.append(r)\n",
    "\n",
    "resultsDF = pd.DataFrame()\n",
    "resultsDF[\"label\"] = llist\n",
    "resultsDF[\"Engineering\"] = flist\n",
    "resultsDF[\"model\"] = mlist\n",
    "resultsDF[\"nFeatures\"] = featureList\n",
    "resultsDF[\"F1\"] = f1List\n",
    "resultsDF[\"Accuracy\"] = accuracyList\n",
    "resultsDF[\"truePos\"] = truePosList\n",
    "resultsDF[\"trueNeg\"] = trueNegList\n",
    "resultsDF[\"falsePos\"] = falsePosList\n",
    "resultsDF[\"falseNeg\"] = falseNegList\n",
    "resultsDF[\"predictions\"] = predictions\n",
    "resultsDF[\"randomSeed\"] = rseed\n",
    "\n",
    "resultsDF.to_csv(\"results/\" + name + str(split) + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsDF.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
